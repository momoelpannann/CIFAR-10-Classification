{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "import torchvision.models as models\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load , Resize and Normalise the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 5000 training images and 1000 test images.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define transformations for feature extraction\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ImageNet\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../Data/RawData', train=True, download=False, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../Data/RawData', train=False, download=False, transform=transform)\n",
    "\n",
    "# Function to filter the dataset\n",
    "def select_images(dataset, num_images_per_class):\n",
    "    class_dict = defaultdict(list)\n",
    "    \n",
    "    # Organize images by class\n",
    "    for idx, (image, label) in enumerate(dataset):\n",
    "        class_dict[label].append((image, label))\n",
    "        \n",
    "        # Stop if we have collected enough images for this class\n",
    "        if len(class_dict[label]) >= num_images_per_class:\n",
    "            continue\n",
    "    \n",
    "    # Select the first num_images_per_class for each class\n",
    "    selected_images = []\n",
    "    for label in range(10):  # CIFAR-10 has 10 classes\n",
    "        selected_images.extend(class_dict[label][:num_images_per_class])\n",
    "    \n",
    "    return selected_images\n",
    "\n",
    "# Select 500 training images and 100 test images per class\n",
    "num_train_images_per_class = 500\n",
    "num_test_images_per_class = 100\n",
    "\n",
    "selected_train_images = select_images(train_dataset, num_train_images_per_class)\n",
    "selected_test_images = select_images(test_dataset, num_test_images_per_class)\n",
    "\n",
    "# Convert selected images to separate lists of images and labels\n",
    "train_images, train_labels = zip(*selected_train_images)\n",
    "test_images, test_labels = zip(*selected_test_images)\n",
    "\n",
    "# Convert to tensors\n",
    "train_images = torch.stack(train_images)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_images = torch.stack(test_images)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "print(f'Selected {len(train_images)} training images and {len(test_images)} test images.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process The Images with Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedelpannann/Documents/Uni Semester 6/COMP 472/Project/Comp472_Project/aiproject/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/mohamedelpannann/Documents/Uni Semester 6/COMP 472/Project/Comp472_Project/aiproject/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature vectors: torch.Size([5000, 512]) for training images and torch.Size([1000, 512]) for test images.\n"
     ]
    }
   ],
   "source": [
    "# Create a custom dataset for the selected images\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# Create custom datasets\n",
    "train_custom_dataset = CustomDataset(train_images, train_labels)\n",
    "test_custom_dataset = CustomDataset(test_images, test_labels)\n",
    "\n",
    "# Create DataLoader for training and test datasets\n",
    "train_loader = DataLoader(train_custom_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_custom_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# Load the pre-trained ResNet-18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Remove the last fully connected layer\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def extract_features(data_loader):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for images, labels in data_loader:\n",
    "        images = images.to(device)  # Move images to GPU\n",
    "        labels = labels.to(device)  # Move labels to GPU (if needed, but not required for feature extraction)\n",
    "        with torch.no_grad():  # No gradient computation needed\n",
    "            features = model(images)  # Forward pass through the model\n",
    "            features = features.view(features.size(0), -1)  # Flatten the features\n",
    "        \n",
    "        features_list.append(features)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    return torch.cat(features_list), torch.cat(labels_list)\n",
    "\n",
    "\n",
    "# Extract features for training and test images\n",
    "train_features, train_labels = extract_features(train_loader)\n",
    "test_features, test_labels = extract_features(test_loader)\n",
    "\n",
    "print(f'Extracted feature vectors: {train_features.shape} for training images and {test_features.shape} for test images.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape Images with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced feature vectors shape: torch.Size([5000, 50]) for training images\n",
      "Reduced feature vectors shape: torch.Size([1000, 50]) for test images\n"
     ]
    }
   ],
   "source": [
    "# Convert features to NumPy arrays for PCA\n",
    "train_features_np = train_features.cpu().numpy()  # Convert to numpy array if using GPU\n",
    "test_features_np = test_features.cpu().numpy()    # Convert to numpy array if using GPU\n",
    "\n",
    "# Initialize PCA\n",
    "pca = PCA(n_components=50)  # We want to reduce to 50 components\n",
    "\n",
    "# Fit PCA on training features\n",
    "pca.fit(train_features_np)\n",
    "\n",
    "# Transform both training and test features\n",
    "train_features_reduced = pca.transform(train_features_np)\n",
    "test_features_reduced = pca.transform(test_features_np)\n",
    "\n",
    "# Convert back to PyTorch tensors if needed\n",
    "train_features_reduced_tensor = torch.tensor(train_features_reduced)\n",
    "test_features_reduced_tensor = torch.tensor(test_features_reduced)\n",
    "\n",
    "# Print shapes of the reduced features\n",
    "print(f'Reduced feature vectors shape: {train_features_reduced_tensor.shape} for training images')\n",
    "print(f'Reduced feature vectors shape: {test_features_reduced_tensor.shape} for test images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Images with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training features and labels as a dictionary\n",
    "torch.save({\n",
    "    'features': train_features_reduced_tensor,\n",
    "    'labels': train_labels\n",
    "}, '../Data/ProcessedData/train_data.pth')\n",
    "\n",
    "# Save test features and labels as a dictionary\n",
    "torch.save({\n",
    "    'features': test_features_reduced_tensor,\n",
    "    'labels': test_labels\n",
    "}, '../Data/ProcessedData/test_data.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data to test if the saving process is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Training Features Shape: torch.Size([5000, 50])\n",
      "Loaded Training Labels Shape: torch.Size([5000])\n",
      "Loaded Test Features Shape: torch.Size([5000, 50])\n",
      "Loaded Test Labels Shape: torch.Size([5000])\n",
      "First training feature vector: tensor([ 5.9841e+00, -3.6731e+00, -1.4204e+00,  1.4349e+00, -2.7493e+00,\n",
      "         4.4789e-01, -2.9624e-01,  3.0293e-01, -2.0248e+00,  1.3278e+00,\n",
      "         2.4916e+00,  5.6473e-03,  6.6921e-01, -1.8713e+00, -1.0279e+00,\n",
      "         1.4384e+00,  1.5166e+00,  8.8583e-01, -2.6691e+00, -1.0197e+00,\n",
      "         2.2547e+00, -5.5619e-01,  3.2156e+00, -4.9057e-01, -1.1145e-01,\n",
      "         8.6599e-01,  1.2758e+00, -1.2245e-01, -3.3557e-01,  7.2982e-01,\n",
      "        -1.7007e+00, -1.6288e+00, -1.1737e+00, -1.6764e+00, -1.5883e+00,\n",
      "        -7.5804e-02, -5.3719e-01, -8.8505e-01, -3.0720e+00,  1.1160e+00,\n",
      "         3.0222e-01,  2.0894e-01, -8.8151e-01, -5.7156e-01,  4.7041e-01,\n",
      "         1.5313e+00, -7.0307e-01, -1.3531e+00,  7.1378e-01,  1.7253e+00])\n",
      "First training label: 8\n",
      "First test feature vector: tensor([ 5.9841e+00, -3.6731e+00, -1.4204e+00,  1.4349e+00, -2.7493e+00,\n",
      "         4.4789e-01, -2.9624e-01,  3.0293e-01, -2.0248e+00,  1.3278e+00,\n",
      "         2.4916e+00,  5.6473e-03,  6.6921e-01, -1.8713e+00, -1.0279e+00,\n",
      "         1.4384e+00,  1.5166e+00,  8.8583e-01, -2.6691e+00, -1.0197e+00,\n",
      "         2.2547e+00, -5.5619e-01,  3.2156e+00, -4.9057e-01, -1.1145e-01,\n",
      "         8.6599e-01,  1.2758e+00, -1.2245e-01, -3.3557e-01,  7.2982e-01,\n",
      "        -1.7007e+00, -1.6288e+00, -1.1737e+00, -1.6764e+00, -1.5883e+00,\n",
      "        -7.5804e-02, -5.3719e-01, -8.8505e-01, -3.0720e+00,  1.1160e+00,\n",
      "         3.0222e-01,  2.0894e-01, -8.8151e-01, -5.7156e-01,  4.7041e-01,\n",
      "         1.5313e+00, -7.0307e-01, -1.3531e+00,  7.1378e-01,  1.7253e+00])\n",
      "First test label: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/98zc9v0x1j7f3xfskw_mln740000gn/T/ipykernel_13813/2924474267.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load('../Data/ProcessedData/train_data.pth')\n",
      "/var/folders/k3/98zc9v0x1j7f3xfskw_mln740000gn/T/ipykernel_13813/2924474267.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load('../Data/ProcessedData/train_data.pth')\n"
     ]
    }
   ],
   "source": [
    "# Load training features and labels\n",
    "train_data = torch.load('../Data/ProcessedData/train_data.pth')\n",
    "train_features_loaded = train_data['features']\n",
    "train_labels_loaded = train_data['labels']\n",
    "\n",
    "# Load test features and labels\n",
    "test_data = torch.load('../Data/ProcessedData/train_data.pth')\n",
    "test_features_loaded = test_data['features']\n",
    "test_labels_loaded = test_data['labels']\n",
    "\n",
    "# Check if the loaded data is correct\n",
    "print(f'Loaded Training Features Shape: {train_features_loaded.shape}')\n",
    "print(f'Loaded Training Labels Shape: {train_labels_loaded.shape}')\n",
    "print(f'Loaded Test Features Shape: {test_features_loaded.shape}')\n",
    "print(f'Loaded Test Labels Shape: {test_labels_loaded.shape}')\n",
    "\n",
    "# Optionally, you can check the first few items to verify the contents\n",
    "print(f'First training feature vector: {train_features_loaded[0]}')\n",
    "print(f'First training label: {train_labels_loaded[0]}')\n",
    "print(f'First test feature vector: {test_features_loaded[0]}')\n",
    "print(f'First test label: {test_labels_loaded[0]}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
